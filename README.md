# AI-Powered Task Manager API üöÄ

A production-ready REST API service built with FastAPI and PostgreSQL that manages tasks with AI-powered summaries and priority suggestions.
<img width="1316" height="847" alt="Screenshot 2026-01-07 111001" src="https://github.com/user-attachments/assets/e0cc5a90-fa76-4dc8-8eae-6e0fe8dc2e8a" />


## üìë Table of Contents

- [Problem Understanding & Assumptions](#problem-understanding--assumptions)
- [Design Decisions](#design-decisions)
- [Solution Approach](#solution-approach)
- [Error Handling Strategy](#error-handling-strategy)
- [How to Run the Project](#how-to-run-the-project)
- [API Documentation](#api-documentation)
- [Testing](#testing)

---

## 1Ô∏è‚É£ Problem Understanding & Assumptions

### Core Interpretation

This project implements a REST API that bridges local database operations with external AI services. The service demonstrates:
- **State Management**: All operations persist to PostgreSQL
- **External Integration**: AI-powered task analysis using Anthropic's Claude API
- **Strict Validation**: Comprehensive input validation using Pydantic
- **Proper HTTP Semantics**: Correct status codes and RESTful design

### Use Case: AI-Powered Task Management

The system allows users to:
1. Create tasks with automatic AI-generated summaries and priority suggestions
2. Retrieve tasks with filtering capabilities
3. Update task properties
4. Delete completed or obsolete tasks

**Real-world scenario**: A project manager creates a task with a detailed description. The AI analyzes the content and:
- Generates a concise summary for quick reference
- Suggests a priority level (low/medium/high) based on urgency indicators in the text

### Key Assumptions

#### Data Format Assumptions
- **Task titles**: Limited to 200 characters to ensure database index efficiency
- **Task descriptions**: Limited to 5000 characters to prevent abuse while allowing detailed descriptions
- **Status values**: Restricted to `todo`, `in_progress`, `done` for consistency
- **Priority values**: Restricted to `low`, `medium`, `high` for simplicity

#### External API Reliability
- **Assumption**: The AI service may experience intermittent downtime or rate limiting
- **Mitigation**: Implemented retry logic (2 retries) and graceful degradation
- **Fallback**: Tasks are created without AI features if the service is unavailable

#### Business Logic Constraints
- **No Authentication**: Assumed single-tenant application (can be extended)
- **No User Context**: Tasks are global, not user-specific
- **Soft Priority Override**: User-provided priority takes precedence over AI suggestions
- **Idempotency**: No duplicate prevention on creation (can be added based on requirements)

#### Performance Assumptions
- **Expected Load**: < 1000 requests/minute
- **Database Size**: Up to 1 million tasks
- **Concurrent Users**: Up to 100
- **AI API Latency**: 1-3 seconds average, 10 seconds timeout

#### Why These Assumptions Matter
- The 200-character title limit enables efficient B-tree indexing
- The retry logic balances reliability vs. user wait time
- Graceful degradation ensures the core task management works even if AI fails
- The status/priority enums prevent data inconsistency

---

## 2Ô∏è‚É£ Design Decisions

### Database Schema Design

```sql
CREATE TABLE tasks (
    id SERIAL PRIMARY KEY,
    title VARCHAR(200) NOT NULL,
    description TEXT NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT 'todo',
    priority VARCHAR(20) NOT NULL DEFAULT 'medium',
    ai_summary TEXT,
    ai_suggested_priority VARCHAR(20),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for query optimization
CREATE INDEX idx_tasks_title ON tasks(title);
CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_priority ON tasks(priority);
CREATE INDEX idx_tasks_created_at ON tasks(created_at);
CREATE INDEX idx_status_priority ON tasks(status, priority);
```

**Rationale:**
- **Primary Key**: Auto-incrementing integer for simplicity and performance
- **Separate AI columns**: Keeps AI-generated data distinct from user input
- **Timestamps**: Enable audit trails and sorting by creation/modification
- **Composite Index** (`status`, `priority`): Optimizes the common query pattern of filtering by both fields
- **NOT NULL constraints**: Enforces data integrity at the database level

### Project Structure

```
project/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py       # Database connection and session management
‚îÇ   ‚îú‚îÄ‚îÄ models.py         # SQLAlchemy ORM models
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py        # Pydantic validation schemas
‚îÇ   ‚îú‚îÄ‚îÄ services.py       # External API integration (AI service)
‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py     # Custom exception classes
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py       # Comprehensive API tests
‚îú‚îÄ‚îÄ main.py               # FastAPI application and endpoints
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md
```

**Architecture Pattern**: **Layered Architecture**
- **Presentation Layer** (`main.py`): API endpoints and request handling
- **Business Logic Layer** (`services.py`): AI integration and business rules
- **Data Access Layer** (`database.py`, `models.py`): Database operations
- **Validation Layer** (`schemas.py`): Request/response contracts

**Benefits:**
- Clear separation of concerns
- Easy to test each layer independently
- Scalable - can extract services to microservices later
- Follows FastAPI best practices

### Validation Logic

**Three Levels of Validation:**

1. **Type Validation** (Pydantic automatic):
   ```python
   title: str  # Must be a string
   status: TaskStatus  # Must be a valid enum value
   ```

2. **Constraint Validation** (Pydantic Field):
   ```python
   title: str = Field(min_length=1, max_length=200)
   ```

3. **Custom Business Logic Validation** (Validators):
   ```python
   @field_validator('title')
   @classmethod
   def title_not_empty(cls, v: str) -> str:
       if not v.strip():
           raise ValueError('Title cannot be empty or whitespace only')
       return v.strip()
   ```

**Why This Matters:**
- Prevents garbage data from entering the database
- Provides clear error messages to API consumers
- Reduces the need for defensive programming in business logic
- Ensures data consistency across the application

### External API Design

**AI Service Architecture:**

```python
class AIService:
    - Timeout protection: 10 seconds
    - Retry logic: 2 retries with exponential backoff
    - Error categorization: Network vs. API vs. Parsing errors
    - Graceful degradation: App continues if AI fails
```

**Design Choices:**
- **Async/Await**: Non-blocking I/O for better concurrency
- **Dependency Injection**: Easy to mock for testing
- **Timeout**: Prevents hanging requests from blocking the server
- **Retry Logic**: Handles transient network failures
- **Structured Logging**: Facilitates debugging and monitoring

**Rate Limiting Consideration:**
- Currently relies on Anthropic's rate limits
- Can be extended with `slowapi` or Redis-based rate limiting
- Estimated cost: ~$0.001 per task creation (using Claude)

---

## 3Ô∏è‚É£ Solution Approach

### Data Flow Walkthrough

#### POST /tasks (Create Task with AI Analysis)

```
1. Client Request
   ‚Üì
2. Pydantic Validation (TaskCreate schema)
   - Validates title length (1-200 chars)
   - Validates description length (1-5000 chars)
   - Validates status enum
   - Strips whitespace
   ‚Üì
3. AI Service Call
   - Constructs prompt with task details
   - Calls Anthropic API with retry logic
   - Parses JSON response
   - Validates AI response structure
   ‚Üì
4. Database Operation
   - Creates Task model instance
   - Populates user data + AI data
   - Commits to PostgreSQL
   - Handles SQLAlchemy errors
   ‚Üì
5. Response Serialization
   - Converts ORM model to Pydantic schema
   - Returns 201 Created with full task data
```

**Error Paths:**
- **Validation Error (422)**: Invalid input ‚Üí detailed error message
- **AI Service Down (201)**: Task created without AI features
- **Database Error (500)**: Transaction rolled back, error logged

#### GET /tasks (Retrieve with Filtering)

```
1. Client Request with Query Params
   ‚Üì
2. Query Building
   - Base query: SELECT * FROM tasks
   - Apply status filter if provided
   - Apply priority filter if provided
   - Apply pagination (skip/limit)
   ‚Üì
3. Database Query Execution
   - SQLAlchemy generates optimized SQL
   - Uses indexes for efficient filtering
   ‚Üì
4. Response Serialization
   - Converts list of ORM models to schemas
   - Returns 200 OK with task array
```

#### PUT /tasks/{task_id} (Update Task)

```
1. Client Request with Partial Data
   ‚Üì
2. Pydantic Validation (TaskUpdate schema)
   - Validates only provided fields
   - Allows null for optional fields
   ‚Üì
3. Database Operation
   - Query task by ID
   - Return 404 if not found
   - Update only provided fields
   - Automatic updated_at timestamp
   - Commit transaction
   ‚Üì
4. Response Serialization
   - Returns 200 OK with updated task
```

#### DELETE /tasks/{task_id}

```
1. Client Request with Task ID
   ‚Üì
2. Database Operation
   - Query task by ID
   - Return 404 if not found
   - Delete from database
   - Commit transaction
   ‚Üì
3. Response
   - Returns 204 No Content (success)
```

---

## 4Ô∏è‚É£ Error Handling Strategy

### Global Exception Handlers

**1. TaskNotFoundError ‚Üí 404 Not Found**
```python
@app.exception_handler(TaskNotFoundError)
async def task_not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={"detail": str(exc)}
    )
```

**2. ExternalAPIError ‚Üí 503 Service Unavailable**
```python
@app.exception_handler(ExternalAPIError)
async def external_api_handler(request, exc):
    return JSONResponse(
        status_code=503,
        content={"detail": f"External API error: {str(exc)}"}
    )
```

**3. SQLAlchemyError ‚Üí 500 Internal Server Error**
```python
@app.exception_handler(SQLAlchemyError)
async def database_exception_handler(request, exc):
    logger.error(f"Database error: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={"detail": "Database operation failed"}
    )
```

### Failure Scenarios & Mitigation

| Scenario | Detection | Response | User Impact |
|----------|-----------|----------|-------------|
| Database connection lost | SQLAlchemy raises OperationalError | Return 500, log error, rely on connection pool retry | Request fails, but subsequent requests may succeed |
| AI API timeout | httpx.TimeoutException after 10s | Retry 2x, then create task without AI | Task created, but no AI features |
| AI API rate limit | HTTP 429 response | Retry with backoff, then graceful degradation | Task created after delay or without AI |
| Invalid AI response format | JSON parse error | Log error, create task without AI | Task created successfully |
| Malformed client request | Pydantic ValidationError | Return 422 with detailed errors | Clear feedback to fix request |

### Resilience Features

**1. Database Connection Pooling**
```python
engine = create_engine(
    DATABASE_URL,
    pool_pre_ping=True,      # Verify connections before use
    pool_size=10,            # Maintain 10 connections
    max_overflow=20          # Allow 20 additional connections
)
```

**2. AI Service Retry Logic**
```python
for attempt in range(self.max_retries + 1):
    try:
        # API call
    except httpx.TimeoutException:
        if attempt == self.max_retries:
            raise ExternalAPIError("AI service timeout")
```

**3. Graceful Degradation**
```python
try:
    ai_analysis = await ai_service.analyze_task(...)
except ExternalAPIError:
    # Continue without AI features
    logger.warning("Creating task without AI features")
```

**4. Transaction Management**
```python
try:
    db.add(task)
    db.commit()
except SQLAlchemyError:
    db.rollback()  # Automatic rollback on error
    raise
```

---

## 5Ô∏è‚É£ How to Run the Project

### Prerequisites

- Python 3.10+
- PostgreSQL 13+
- Anthropic API key (get from https://console.anthropic.com)

### Option 1: Local Setup

**Step 1: Clone and Setup Environment**
```bash
# Clone the repository
git clone <repository-url>
cd task-manager-api

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

**Step 2: Configure Database**
```bash
# Install PostgreSQL (if not already installed)
# macOS: brew install postgresql
# Ubuntu: sudo apt-get install postgresql

# Start PostgreSQL
# macOS: brew services start postgresql
# Ubuntu: sudo service postgresql start

# Create database
createdb taskmanager
```

**Step 3: Configure Environment Variables**
```bash
# Copy example environment file
cp .env.example .env

# Edit .env with your settings
nano .env
```

**.env file:**
```bash
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/taskmanager
ANTHROPIC_API_KEY=your_actual_api_key_here
```

**Step 4: Run the Application**
```bash
# Start the server
uvicorn main:app --reload

# Server will start at http://localhost:8000
# Swagger docs at http://localhost:8000/docs
# ReDoc at http://localhost:8000/redoc
```

### Option 2: Docker Setup (Recommended)

**Step 1: Setup Environment**
```bash
# Clone and configure
git clone <repository-url>
cd task-manager-api
cp .env.example .env

# Edit .env with your API key
nano .env
```

**Step 2: Run with Docker Compose**
```bash
# Build and start all services
docker-compose up --build

# Or run in detached mode
docker-compose up -d

# View logs
docker-compose logs -f api
```

**Step 3: Access the Application**
- API: http://localhost:8000
- Swagger UI: http://localhost:8000/docs
- PostgreSQL: localhost:5432

**Step 4: Stop Services**
```bash
docker-compose down

# Remove volumes (data)
docker-compose down -v
```

---

## üìñ API Documentation

### Interactive Documentation

Once the server is running, access:
- **Swagger UI**: http://localhost:8000/docs (interactive testing)
- **ReDoc**: http://localhost:8000/redoc (detailed documentation)

### Example API Calls

#### 1. Create Task (POST /tasks)

**cURL:**
```bash
curl -X POST "http://localhost:8000/tasks" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Implement user authentication",
    "description": "Add JWT-based authentication with refresh tokens. Need to implement login, logout, and token refresh endpoints. High priority due to security requirements.",
    "status": "todo"
  }'
```

**Response (201 Created):**
```json
{
  "id": 1,
  "title": "Implement user authentication",
  "description": "Add JWT-based authentication with refresh tokens...",
  "status": "todo",
  "priority": "high",
  "ai_summary": "Implement JWT authentication with token refresh functionality",
  "ai_suggested_priority": "high",
  "created_at": "2024-01-15T10:30:00Z",
  "updated_at": "2024-01-15T10:30:00Z"
}
```

#### 2. Get All Tasks (GET /tasks)

**cURL:**
```bash
# Get all tasks
curl -X GET "http://localhost:8000/tasks"

# With filtering
curl -X GET "http://localhost:8000/tasks?status_filter=todo&priority_filter=high"

# With pagination
curl -X GET "http://localhost:8000/tasks?skip=0&limit=10"
```

**Response (200 OK):**
```json
[
  {
    "id": 1,
    "title": "Implement user authentication",
    "status": "todo",
    "priority": "high",
    ...
  },
  {
    "id": 2,
    "title": "Write API documentation",
    "status": "in_progress",
    "priority": "medium",
    ...
  }
]
```

#### 3. Get Single Task (GET /tasks/{id})

**cURL:**
```bash
curl -X GET "http://localhost:8000/tasks/1"
```

**Response (200 OK):**
```json
{
  "id": 1,
  "title": "Implement user authentication",
  ...
}
```

**Error Response (404 Not Found):**
```json
{
  "detail": "Task with id 999 not found"
}
```

#### 4. Update Task (PUT /tasks/{id})

**cURL:**
```bash
# Update status
curl -X PUT "http://localhost:8000/tasks/1" \
  -H "Content-Type: application/json" \
  -d '{
    "status": "in_progress"
  }'

# Update multiple fields
curl -X PUT "http://localhost:8000/tasks/1" \
  -H "Content-Type: application/json" \
  -d '{
    "status": "done",
    "priority": "low"
  }'
```

**Response (200 OK):**
```json
{
  "id": 1,
  "title": "Implement user authentication",
  "status": "in_progress",
  "priority": "high",
  ...
}
```

#### 5. Delete Task (DELETE /tasks/{id})

**cURL:**
```bash
curl -X DELETE "http://localhost:8000/tasks/1"
```

**Response (204 No Content):** *(Empty body)*

**Error Response (404 Not Found):**
```json
{
  "detail": "Task with id 999 not found"
}
```

#### 6. Health Check (GET /health)

**cURL:**
```bash
curl -X GET "http://localhost:8000/health"
```

**Response (200 OK):**
```json
{
  "status": "healthy"
}
```

### Postman Collection

Import this JSON into Postman for quick testing:

```json
{
  "info": {
    "name": "Task Manager API",
    "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
  },
  "item": [
    {
      "name": "Create Task",
      "request": {
        "method": "POST",
        "header": [{"key": "Content-Type", "value": "application/json"}],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"title\": \"Sample Task\",\n  \"description\": \"This is a sample task description\"\n}"
        },
        "url": "http://localhost:8000/tasks"
      }
    },
    {
      "name": "Get All Tasks",
      "request": {
        "method": "GET",
        "url": "http://localhost:8000/tasks"
      }
    },
    {
      "name": "Get Task by ID",
      "request": {
        "method": "GET",
        "url": "http://localhost:8000/tasks/1"
      }
    },
    {
      "name": "Update Task",
      "request": {
        "method": "PUT",
        "header": [{"key": "Content-Type", "value": "application/json"}],
        "body": {
          "mode": "raw",
          "raw": "{\n  \"status\": \"done\"\n}"
        },
        "url": "http://localhost:8000/tasks/1"
      }
    },
    {
      "name": "Delete Task",
      "request": {
        "method": "DELETE",
        "url": "http://localhost:8000/tasks/1"
      }
    }
  ]
}
```

---

## üß™ Testing

### Running Tests

**Run all tests:**
```bash
pytest
```

**Run with coverage report:**
```bash
pytest --cov=app --cov-report=html
# Open htmlcov/index.html in browser
```

**Run specific test class:**
```bash
pytest tests/test_api.py::TestTaskCreation
```

**Run with verbose output:**
```bash
pytest -v
```

### Test Coverage

Current test coverage: **~85%**

**Covered Areas:**
- ‚úÖ All CRUD operations
- ‚úÖ Input validation (empty, too long, invalid types)
- ‚úÖ Filtering and pagination
- ‚úÖ Error scenarios (404, 422, 500, 503)
- ‚úÖ AI service integration (with mocking)
- ‚úÖ Database operations

**Test Structure:**
```
tests/test_api.py
‚îú‚îÄ‚îÄ TestTaskCreation (7 tests)
‚îÇ   ‚îú‚îÄ‚îÄ test_create_task_success
‚îÇ   ‚îú‚îÄ‚îÄ test_create_task_with_explicit_priority
‚îÇ   ‚îú‚îÄ‚îÄ test_create_task_invalid_status
‚îÇ   ‚îú‚îÄ‚îÄ test_create_task_missing_title
‚îÇ   ‚îú‚îÄ‚îÄ test_create_task_empty_title
‚îÇ   ‚îî‚îÄ‚îÄ test_create_task_title_too_long
‚îú‚îÄ‚îÄ TestTaskRetrieval (6 tests)
‚îÇ   ‚îú‚îÄ‚îÄ test_get_all_tasks_empty
‚îÇ   ‚îú‚îÄ‚îÄ test_get_all_tasks
‚îÇ   ‚îú‚îÄ‚îÄ test_get_tasks_with_status_filter
‚îÇ   ‚îú‚îÄ‚îÄ test_get_tasks_with_priority_filter
‚îÇ   ‚îú‚îÄ‚îÄ test_get_task_by_id
‚îÇ   ‚îî‚îÄ‚îÄ test_get_nonexistent_task
‚îú‚îÄ‚îÄ TestTaskUpdate (4 tests)
‚îÇ   ‚îú‚îÄ‚îÄ test_update_task_success
‚îÇ   ‚îú‚îÄ‚îÄ test_update_task_partial
‚îÇ   ‚îú‚îÄ‚îÄ test_update_nonexistent_task
‚îÇ   ‚îî‚îÄ‚îÄ test_update_task_invalid_data
‚îú‚îÄ‚îÄ TestTaskDeletion (2 tests)
‚îÇ   ‚îú‚îÄ‚îÄ test_delete_task_success
‚îÇ   ‚îî‚îÄ‚îÄ test_delete_nonexistent_task
‚îî‚îÄ‚îÄ TestAIServiceIntegration (2 tests)
    ‚îú‚îÄ‚îÄ test_ai_service_success
    ‚îî‚îÄ‚îÄ test_ai_service_timeout
```

### Mocking Strategy

**Database Mocking:**
- Uses SQLite in-memory database for tests
- Fast and isolated from production data
- Automatic cleanup after each test

**AI Service Mocking:**
- Uses `unittest.mock.AsyncMock`
- Simulates successful responses and failures
- No actual API calls during testing

**Example Mock:**
```python
def override_ai_service():
    service = AIService()
    service.analyze_task = AsyncMock(return_value={
        "summary": "Test task summary",
        "suggested_priority": "high"
    })
    return service
```

---

## üîß Development

### Code Quality Tools

**Linting:**
```bash
# Install linters
pip install flake8 black isort

# Run linters
flake8 app tests
black --check app tests
isort --check-only app tests
```

**Auto-formatting:**
```bash
black app tests
isort app tests
```

### Project Checklist

- [x] Four REST endpoints (POST, GET, PUT, DELETE)
- [x] PostgreSQL integration with SQLAlchemy
- [x] External API integration (Anthropic Claude)
- [x] Pydantic validation for all schemas
- [x] Proper HTTP status codes
- [x] Global exception handlers
- [x] Comprehensive test suite (21 tests)
- [x] Docker support
- [x] Detailed documentation
- [x] Error handling and retry logic
- [x] Database indexing for performance
- [x] Async/await for concurrency

---

## üìù Future Enhancements

### Authentication & Authorization
- Add JWT-based authentication
- Implement user-specific task isolation
- Role-based access control (admin, user)

### Performance Optimizations
- Redis caching for frequently accessed tasks
- Database query optimization with `select_in_load`
- Background task processing with Celery
- Rate limiting with `slowapi`

### Feature Additions
- Task categories and tags
- Due dates and reminders
- Task assignment to multiple users
- File attachments
- Full-text search with PostgreSQL FTS
- WebSocket support for real-time updates

### Observability
- Structured logging with `structlog`
- Metrics with Prometheus
- Distributed tracing with OpenTelemetry
- Health checks for dependencies

---

## üìÑ License

MIT License

## üë§ Author

Backend Engineer Take-Home Assessment

---

## ü§ù Contributing

This is an assessment project, but feedback is welcome! Please open an issue for suggestions.

---

**Note:** This project demonstrates production-ready patterns but should be extended with proper authentication, monitoring, and scaling considerations for real-world deployment.
